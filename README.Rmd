---
title: "Workshop: Doing Sequence Analysis"
author: Kamila Kolpashnikova^[University of Oxford]

output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
## Introduction

This is a document for the workshop prepared in 2020 for the Department of Sociology. 

To follow this tutotial, you need to have the harmonized version of the Taiwan 2004 time use data and access to it.

* change the directory to the location of your file
* follow instructions in the code (R file is included)

Funding: This project has received funding from the European Unionâ€™s Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No 892101 (awardee: Kamila Kolpashnikova). 

## History of SA in Social Sciences

Although sequence analysis has been used for a long time, it only took off in social science since the development of TraMineR package in R (thanks to Geneva team).
The name of the package is commonly pronounced as truh-mai-ner, but it is likely that originally it should be truh-mee-ner because it's a type of grape.

It is important to remember that sequence analysis is largely a descriptive technique. It does not aim to establish causal links.

## Loading Necessary Packages

```{r}
if (!require("pacman")) install.packages("pacman")
library(pacman)

# load and install packages
pacman::p_load(TraMineR, TraMineRextras, cluster, RColorBrewer, devtools, haven, 
               tidyverse, reshape2, WeightedCluster, nnet)
```

## Load .dta (Stata) Dataset
Remember that in r, it's forward slashes.
Unlike read.dta, read_dta reads all versions of stata files.


```{r}
data<-read_dta("~/Dropbox/GenTime research - shared all/workshopSA/Taiwan 2004 sequences.dta")

## create id if id is not present in the dataset
data$id <- as.numeric(paste(data$HLDID, data$PERSID, sep = ""))
```

Specify the names for the activity variables. These are the names we harmonized using the agreed naming conventions.

```{r}
activities<-c()
for(i in 1:96) {
  activities<-c(activities, paste("act_h", i, sep = ""))
}

activities
```


## Sequence Analysis 

I created an object with time intervals' labels. Sequences start at 00:00 AM (for the Taiwanese dataset).
Depending on your own sequence intervals, these labels need to be adjusted accordingly.

```{r}
t_intervals_labels <-  c("00:00", "00:15","00:30","00:45",
                         "01:00", "01:15","01:30","01:45",
                         "02:00", "02:15","02:30","02:45",
                         "03:00", "03:15","03:30","03:45",
                         "04:00", "04:15","04:30","04:45",
                         "05:00", "05:15","05:30","05:45",
                         "06:00", "06:15","06:30","06:45",
                         "07:00", "07:15","07:30","07:45",
                         "08:00", "08:15","08:30","08:45",
                         "09:00", "09:15","09:30","09:45",
                         "10:00", "10:15","10:30","10:45",
                         "11:00", "11:15","11:30","11:45",
                         "12:00", "12:15","12:30","12:45",
                         "13:00", "13:15","13:30","13:45",
                         "14:00", "14:15","14:30","14:45",
                         "15:00", "15:15","15:30","15:45",
                         "16:00", "16:15","16:30","16:45",
                         "17:00", "17:15","17:30","17:45",
                         "18:00", "18:15","18:30","18:45",
                         "19:00", "19:15","19:30","19:45",
                         "20:00", "20:15","20:30","20:45",
                         "21:00", "21:15","21:30","21:45",
                         "22:00", "22:15","22:30","22:45",
                         "23:00", "23:15","23:30","23:45")
```

## Colour Palette

In my experience, brewing colours in R is one of the most painful experiences, especially if you have many categories of activities. Things can get even worse if you have to go grayscale if publishing articles with colour images is too expensive.

Let's brew some colours first.The number of colours is dictated by the number of states (in the alphabet).

Interesting resource on colors [(cheatsheet):](https://www.nceas.ucsb.edu/sites/default/files/2020-04/colorPaletteCheatsheet.pdf)


```{r}
colourCount = 13
getPalette = colorRampPalette(brewer.pal(9, "Set3"))
```

To check the created pallette, you can do the following but define labels first:
```{r}
labels = c("sleep", "selfcare", 
           "eatdrink", "commute",
           "paidwork", "educatn", "housework",
           "shopserv", "TVradio", "leisure", 
           "sportex",
           "volorgwk",
           "other activity")
colourCount = length(labels)
getPalette = colorRampPalette(brewer.pal(9, "Set3"))

## let's see how our colours look like
axisLimit <- sqrt(colourCount)+1
colours=data.frame(x1=rep(seq(1, axisLimit, 1), length.out=colourCount), 
                   x2=rep(seq(2, axisLimit+1, 1), length.out=colourCount), 
                   y1=rep(1:axisLimit, each=axisLimit,length.out=colourCount), 
                   y2=rep(2:(axisLimit+1), each=axisLimit,length.out=colourCount), 
                   t=letters[1:colourCount], r=labels)


ggplot() + 
  scale_x_continuous(name="x") + 
  scale_y_continuous(name="y") +
  geom_rect(data=colours, mapping=aes(xmin=x1, xmax=x2, ymin=y1, ymax=y2, fill=t), color="black", alpha=0.5) +
  geom_text(data=colours, aes(x=x1+(x2-x1)/2, y=y1+(y2-y1)/2, label=r), size=4) + 
  scale_fill_manual(values = getPalette(colourCount)) + theme(legend.position = "none")
```

## Defining Sequence Object

```{r , message=FALSE}
MyData <- as_tibble(data)

## you want to use the full categories of states:
## (you need to change if you only focus on specific activities)
gentime_seq <- seqdef(MyData,
                        var = activities,
                        cnames = t_intervals_labels,
                        alphabet = c("1", "2", "3", "4", "5",
                                     "6", "7", "8","9", "10",
                                     "11", "12", "13"), 
                        labels = c("sleep", "selfcare", 
                                   "eatdrink", "commute",
                                   "paidwork", "educatn", "housework",
                                   "shopserv", "TVradio", "leisure", 
                                   "sportex",
                                   "volorgwk",
                                   "other activity"),
                        cpal = getPalette(colourCount),
                        xtstep = 18, ##step between displayed tick-marks and labels on the time x-axis
                        id = MyData$id)

```
## Weights
If you have weights then add ===>  weights = MyData$Weight in your sequence object definition above.

Check how the sequences look like:
```{r}
print(gentime_seq[1:5, ], format = "SPS")
```

If you use the "STS" format, it will show each step

## Plotting Sequences

- sequence index plots

With a small i, the default for idxs is 1:10, plotting the first 10 sequences.
If you set idxs to 0, it plots all sequences (might take a long time).

```{r}
seqiplot(gentime_seq, border = NA, with.legend = "right", legend.prop=0.4)
```

You can also use the same command with a capital I. It wiil plot all unless you specify idxs option.

```{r}
seqIplot(gentime_seq, border = NA, with.legend = "right", legend.prop=0.4, idxs = 1:4)
```

- the most frequent sequences 

Unfortunately, for time-use data, it is usually useless to plot the most frequent sequences.
If you tabulate 4 frequent sequences you will see what I mean. It is because there are 96 steps there are barely any same sequences.
This command is more useful for shorter sequences with many commonalities (as in life-course research).

```{r}
seqtab(gentime_seq, idxs = 1:4)

## Plot of the 10 most frequent sequences
seqplot(gentime_seq, type="f", with.legend = "right", legend.prop=0.4)

##also can plot frequencies using seqfplot
seqfplot(gentime_seq, border = NA, with.legend = "right", legend.prop=0.4)
##again, frequencies is not very useful for TU seqs
##because very few of them repeat themselves with 96 steps
```

- tempograms 

State distribution plots (aka tempogram aka chronogram)
This is an easy way to plot a tempogram (compared to area plots).

```{r}
seqdplot(gentime_seq, border = NA, with.legend = "right", legend.prop=0.4)
```

## Transitions

```{r}
## transitions from state to state (in probabilities)
trate <- seqtrate(gentime_seq)
round(trate, 2)

## heatmap of the transitions matrix
heatTrate=melt(trate)
ggplot(heatTrate, aes(Var2, Var1)) +
  geom_tile(aes(fill = value)) +
  geom_text(aes(label = round(value, 2))) +
  scale_fill_continuous(high = "#132B43", low = "#56B1F7", name="Transitions")
```

## Changing Granularity (Minutes to Hours, etc.)
TraMineR made it very easy to change the number of steps in a sequence.
*seqgranularity* is the command that will help you do it.

To use the first state to represent all, use method = "first", the last = "last", or the most frequent = "mostfreq".

In the following chunk of code, tspan = 4 means transform to every hour instead of 15 min.

```{r}
gentime4_seq <- seqgranularity(gentime_seq,
                                  tspan=4, method="mostfreq")

seqdplot(gentime4_seq, border = NA, with.legend = "right", legend.prop=0.4)
```

You can see on the tempograms that the granularity decreased and now each step is an hour.

## Modal states sequence 

```{r}
seqplot(gentime_seq, type="ms", with.legend = "right", legend.prop=0.4)
## same as
seqmsplot(gentime4_seq, with.legend = "right", legend.prop=0.4, main="Modal Sequences")
```

## Embrace enthropy

```{r}
seqHtplot(gentime_seq, with.legend = "right", legend.prop=0.4)
```

## Calculating Dissimilarities
Let's subset our sequences b/c it's too big and will take a long time otherwise.

```{r, message=FALSE}
data4om<-seqdef(MyData[1:2000,],
                var = activities,
                cnames = t_intervals_labels,
                alphabet = c("1", "2", "3", "4", "5",
                             "6", "7", "8","9", "10",
                             "11", "12", "13"), ## notice that I don't have 8 ) you might have it check the data
                labels = c("sleep", "selfcare", 
                           "eatdrink", "commute",
                           "paidwork", "educatn", "housework",
                           "shopserv", "TVradio", "leisure", 
                           "sportex",
                           "volorgwk",
                           "other activity"),
                cpal = getPalette(colourCount),
                xtstep = 18, ##step between displayed tick-marks and labels on the time x-axis
                id = MyData[1:2000,]$id)

```

## Substitution Cost Matrix
We need to define the substitution cost for all the transitions (it can be a constant or user-defined).

```{r}
# seqsubm() = to compute own substitution matrix
#"TRATE", the costs are determined from the estimated transition rates
scost <- seqsubm(data4om, method = "TRATE")
round(scost, 3)
## calculated in this way, all are close to 2 anyway (for this dataset) 2 is default
## or we can use the usual default one of constant 2:
ccost <- seqsubm(data4om, method="CONSTANT", cval=2)
round(ccost, 3)
```

## Optimal Matching
Optimal matching for calculating dissimilarities between sequences need the specification of both substitution and indel costs.
The algorithm is developed by Needleman and Wunsch (1970).
For the illustration how the algorithm works please link to
[my explanation of optimal matching](https://blogs.ubc.ca/kamilakolpashnikova/optimal-matching-algorithm-interactive-app-for-social-scientists/)

If the sequence file is heavy, calculate only the upper part of the matrix by full.matrix = FALSE
The usual default is that substitution cost is twice the indel cost, and default indel cost is 1.
```{r}
om_gentime <- seqdist(data4om, method = "OM", indel = 1, sm = scost)
## this results in a dissimilarity matrix which you can look at using:
round(om_gentime[1:10, 1:10], 1)
```

## Cluster Analysis
Let's run cluster analysis on our dissimilarity matrix

Other common methods are:

- "average", 
- "single", 
- "complete"  

The "average" and "single" options do not work well for time-use data (check).
The "complete" option is a possibility (check).
```{r}
clusterward <- agnes(om_gentime, diss = TRUE, method = "ward")

# Convert hclust into a dendrogram and plot
hcd <- as.dendrogram(clusterward)

# Default plot
plot(hcd, type = "rectangle", ylab = "Height")
```

## How good is our clustering?

Let's inspect the splitting tree branches:

```{r}

ward.tree <- as.seqtree(clusterward, seqdata = data4om, 
                            diss = om_gentime, 
                            ncluster = 25)
seqtreedisplay(ward.tree, type = "d", border = NA, show.depth = TRUE) 
```

Test the cluster solution quality:

There are many possible tests:

- PBC. Point Biserial Correlation. Correlation between the given distance matrice and a distance which equal to zero for individuals in the same cluster and one otherwise.
- HG. Hubert's Gamma. Same as previous but using Kendall's Gamma coefficient.
- HGSD. Hubert's Gamma (Somers'D). Same as previous but using Somers' D coefficient.
- ASW. Average Silhouette width (observation).
- ASWw. Average Silhouette width (weighted).
- CH. Calinski-Harabasz index (Pseudo F statistics computed from distances).
- R2. Share of the discrepancy explained by the clustering solution.
- CHsq. Calinski-Harabasz index (Pseudo F statistics computed from squared distances).
- R2sq. Share of the discrepancy explained by the clustering solution (computed using squared distances).
- HC. Hubert's C coefficient.
- ASW. The Average Silhouette Width of each cluster, one column for each ASW measure.

```{r}

wardtest <- as.clustrange(clusterward,
                         diss = om_gentime, 
                          ncluster = 25)

#plot the quality criteria
plot(wardtest, stat = c("ASW", "HC", "PBC"), norm = "zscore", lwd = 4)
```

Let's say that our solution is pretty good for 10 clusters. 

1. Cut the tree

```{r}
MyData<-MyData[1:2000,]
c10 <- cutree(clusterward, k = 10)
MyData<-cbind(MyData, c10)
```

2. Plot the cluster solution (will save in the working directory)

```{r}
png("test.png", 1200, 800)
seqdplot(data4om, group = c10, border = NA)
dev.off()
```

## How to plot a cluster

```{r}
# subset data by cluster
cl1<-(data4om[MyData$c10 ==  "1",])

# plot the selected cluster 
par(mfrow=c(1,1))
seqdplot(cl1, main = "",
         cex.main = 1.7, 
         with.legend = FALSE, 
         yaxis = FALSE, 
         cpal = getPalette(colourCount), 
         ylab = "",
         border = NA)
```

## Multinomial Regression on the Clusters

For more details please consult the nnet library documents.

```{r}
# Format categorical variables
MyData$c10 <- factor(MyData$c10)

# Set the reference group for c1 to be 1
MyData$c10 <- relevel(MyData$c10, ref=1)

# Run the model
model <- multinom(c10~URBAN+SEX+CARER+factor(INCOME), data=MyData, na.action=na.omit)

summary(model)

##Multinomial logit model: relative risk ratios
# Relative risk ratios allow an easier interpretation of the logit coefficients. 
#They are the exponentiatedvalue of the logit coefficients.

multi1.rrr = exp(coef(model))
multi1.rrr
```

[![R build status](https://github.com/Kolpashnikova/SA_workshop_gentime/workflows/R-CMD-check/badge.svg)](https://github.com/Kolpashnikova/SA_workshop_gentime/actions)
